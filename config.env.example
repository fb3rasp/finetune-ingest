# Finetune Ingest - Centralized Pipeline Configuration
# This file is the single source of truth for the `run.py` pipeline.

# =============================================================================
# LLM API Keys (Optional - only needed for OpenAI, Anthropic, Google)
# =============================================================================
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# =============================================================================
# Ollama Configuration (for 'local' provider)
# =============================================================================
OLLAMA_BASE_URL=http://192.168.50.133:11434

# =============================================================================
# Pipeline: Input/Output Directories
# =============================================================================
PIPELINE_INPUT_DIR=_incoming
PIPELINE_CHUNKS_DIR=_data/document_chunks
PIPELINE_QA_DIR=_data/qa_results
PIPELINE_TRAINING_DATA_FILE=_data/results/training_data.json
PIPELINE_VALIDATION_REPORT_FILE=_data/results/validation_report.json
PIPELINE_FILTERED_TRAINING_DATA_FILE=_data/results/training_data_filtered.json
PIPELINE_FINAL_TRAINING_DATA_FILE=_data/results/training_data_final.jsonl

# =============================================================================
# Pipeline: Step 1 - Document Chunking
# =============================================================================
PIPELINE_CHUNK_SIZE=1000
PIPELINE_CHUNK_OVERLAP=200
PIPELINE_SPLITTING_STRATEGY=recursive

# =============================================================================
# Pipeline: Step 2 - Q&A Generation
# =============================================================================
PIPELINE_LLM_PROVIDER=local
PIPELINE_LLM_MODEL=qwen3:14b # llama3.2:latest 
PIPELINE_QUESTIONS_PER_CHUNK=3
PIPELINE_TEMPERATURE=0.3
PIPELINE_MAX_TOKENS=6000
PIPELINE_REASONING=false

# =============================================================================
# Pipeline: Step 3 - Validation
# =============================================================================
PIPELINE_VALIDATOR_PROVIDER=local
PIPELINE_VALIDATOR_MODEL=qwen3:14b
PIPELINE_VALIDATION_THRESHOLD=8.0
PIPELINE_FILTER_THRESHOLD=7.0
PIPELINE_VALIDATOR_REASONING=false

# =============================================================================
# Pipeline: Step 4 - Formatting
# =============================================================================
PIPELINE_TRAINING_TEMPLATE=alpaca

# =============================================================================
# Pipeline: General Settings
# =============================================================================
PIPELINE_VERBOSE=true
PIPELINE_BATCH_SIZE=10
