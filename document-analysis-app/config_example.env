# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini Configuration
GOOGLE_API_KEY=your_google_api_key_here

# Local LLM Configuration (Ollama)
OLLAMA_HOST=http://localhost:11434

# MCP Server Configuration
FINETUNE_INCOMING_DIR=./incoming
FINETUNE_OUTPUT_DIR=./output
FINETUNE_CHUNK_SIZE=1000
FINETUNE_QUESTIONS_PER_CHUNK=3
FINETUNE_DEFAULT_PROVIDER=openai
FINETUNE_DEFAULT_MODEL=
FINETUNE_TEMPERATURE=0.7
FINETUNE_MAX_TOKENS=2000
FINETUNE_LOG_LEVEL=INFO
FINETUNE_LOG_FILE=

# Processing Configuration
DEFAULT_CHUNK_SIZE=1000
DEFAULT_QUESTIONS_PER_CHUNK=3
DEFAULT_OUTPUT_DIR=./output
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000 